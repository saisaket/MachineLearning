{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip \n",
    "import pickle\n",
    "import scipy.sparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST on Python 3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'mnist.pkl.gz'\n",
    "f = gzip.open(filename, 'rb')\n",
    "training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load USPS on Python 3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "USPSMat  = []\n",
    "USPSTar  = []\n",
    "curPath  = 'USPSdata/Numerals'\n",
    "savedImg = []\n",
    "\n",
    "for j in range(0,10):\n",
    "    curFolderPath = curPath + '/' + str(j)\n",
    "    imgs =  os.listdir(curFolderPath)\n",
    "    for img in imgs:\n",
    "        curImg = curFolderPath + '/' + img\n",
    "        if curImg[-3:] == 'png':\n",
    "            img = Image.open(curImg,'r')\n",
    "            img = img.resize((28, 28))\n",
    "            savedImg = img\n",
    "            imgdata = (255-np.array(img.getdata()))/255\n",
    "            USPSMat.append(imgdata)\n",
    "            USPSTar.append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data for Training, Testing and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_img     = training_data[0]\n",
    "training_label   = training_data[1]\n",
    "testing_img      = test_data[0]\n",
    "testing_label    = test_data[1]\n",
    "validation_img   = validation_data[0]\n",
    "validation_label = validation_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION using SOFTMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLoss(w,x,y,lam):\n",
    "    \n",
    "    # takes the length of training\n",
    "    m = x.shape[0] \n",
    "    # converting integer class into one-hot representation\n",
    "    y_mat = oneHotIt(y) \n",
    "    # computing class scores given our input and current weights\n",
    "    scores = np.dot(x,w) \n",
    "    # performing softmax on the scores to get the probabilities\n",
    "    prob = softmax(scores) \n",
    "    # finding the loss of the probabilities\n",
    "    loss = (-1 / m) * np.sum(y_mat * np.log(prob)) + (lam/2)*np.sum(w*w) \n",
    "    # computing the gradient for that loss\n",
    "    grad = (-1 / m) * np.dot(x.T,(y_mat - prob)) + lam*w \n",
    "    return loss,grad\n",
    "\n",
    "def oneHotIt(Y):\n",
    "    m = Y.shape[0]\n",
    "    OHX = scipy.sparse.csr_matrix((np.ones(m), (Y, np.array(range(m)))))\n",
    "    OHX = np.array(OHX.todense()).T\n",
    "    return OHX\n",
    "\n",
    "def softmax(z):\n",
    "    z -= np.max(z)\n",
    "    # softmax transformation\n",
    "    sm = (np.exp(z).T / np.sum(np.exp(z),axis=1)).T\n",
    "    return sm\n",
    "\n",
    "def getPrediction(X):\n",
    "    probs = softmax(np.dot(X,w))\n",
    "    preds = np.argmax(probs,axis=1)\n",
    "    return probs,preds\n",
    "\n",
    "def getAccuracy(X,Y):\n",
    "    prob,prede = getPrediction(X)\n",
    "    accuracy = sum(prede == Y)/(float(len(Y)))\n",
    "    return accuracy,metrics.confusion_matrix(Y, prede),prede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.629679249902\n",
      "Training Accuracy:  0.85808\n",
      "Testing Accuracy:  0.8718\n",
      "Confusion Matrix: \n",
      " [[ 946    0    3    3    0    4   15    1    8    0]\n",
      " [   0 1092    5    3    1    4    4    0   26    0]\n",
      " [  16   19  850   26   19    0   26   23   47    6]\n",
      " [   5    3   22  879    1   32    8   19   27   14]\n",
      " [   3    8    5    0  861    1   17    2   10   75]\n",
      " [  26   14    5   79   23  650   28    9   41   17]\n",
      " [  20    5   13    2   13   19  880    0    6    0]\n",
      " [   4   36   28    1   13    0    4  887   10   45]\n",
      " [   9   14   14   38   11   23   18   14  813   20]\n",
      " [  13   13   11   12   51   11    1   26   11  860]]\n",
      "USPS Accuracy:  0.33206660333\n",
      "USPS Confusion Matrix: \n",
      " [[ 946    0    3    3    0    4   15    1    8    0]\n",
      " [   0 1092    5    3    1    4    4    0   26    0]\n",
      " [  16   19  850   26   19    0   26   23   47    6]\n",
      " [   5    3   22  879    1   32    8   19   27   14]\n",
      " [   3    8    5    0  861    1   17    2   10   75]\n",
      " [  26   14    5   79   23  650   28    9   41   17]\n",
      " [  20    5   13    2   13   19  880    0    6    0]\n",
      " [   4   36   28    1   13    0    4  887   10   45]\n",
      " [   9   14   14   38   11   23   18   14  813   20]\n",
      " [  13   13   11   12   51   11    1   26   11  860]]\n"
     ]
    }
   ],
   "source": [
    "# main section of softmax regression\n",
    "w = np.zeros([training_img.shape[1],len(np.unique(training_label))])\n",
    "lam = 0.001\n",
    "epochs = 1000\n",
    "learningRate = 0.01\n",
    "losses = []\n",
    "# updating weights on each epoch\n",
    "for i in range(0, epochs):\n",
    "    loss,grad = getLoss(w, training_img , training_label, lam)\n",
    "    losses.append(loss)\n",
    "    w = w - (learningRate * grad)\n",
    "\n",
    "print('loss: ', loss)\n",
    "print('Training Accuracy: ', getAccuracy(training_img, training_label)[0])\n",
    "Acc, Con, LogRegPredictions = getAccuracy(testing_img, testing_label)\n",
    "print('Testing Accuracy: ',Acc)\n",
    "print('Confusion Matrix: \\n',Con)\n",
    "uspsAcc, uspsCon, uspsLogRegPredictions = getAccuracy(USPSMat, USPSTar)\n",
    "print('USPS Accuracy: ', uspsAcc)\n",
    "print('USPS Confusion Matrix: \\n',Con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KERAS MULTI LAYER NEURAL NETWORK MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodeLabel(labels):\n",
    "    \n",
    "    processedLabel = []\n",
    "    \n",
    "    for labelInstance in labels:\n",
    "        if(labelInstance == 0):\n",
    "            processedLabel.append([0])\n",
    "        elif(labelInstance == 1):\n",
    "            processedLabel.append([1])\n",
    "        elif(labelInstance == 2):\n",
    "            processedLabel.append([2])\n",
    "        elif(labelInstance == 3):\n",
    "            processedLabel.append([3])\n",
    "        elif(labelInstance == 4):\n",
    "            processedLabel.append([4])\n",
    "        elif(labelInstance == 5):\n",
    "            processedLabel.append([5])\n",
    "        elif(labelInstance == 6):\n",
    "            processedLabel.append([6])\n",
    "        elif(labelInstance == 7):\n",
    "            processedLabel.append([7])\n",
    "        elif(labelInstance == 8):\n",
    "            processedLabel.append([8])\n",
    "        elif(labelInstance == 9):\n",
    "            processedLabel.append([9])\n",
    "    return np_utils.to_categorical(np.array(processedLabel),10)\n",
    "\n",
    "def decodeLabel(encodedLabel):\n",
    "    if encodedLabel == 0:\n",
    "        return 0\n",
    "    elif encodedLabel == 1:\n",
    "        return 1\n",
    "    elif encodedLabel == 2:\n",
    "        return 2\n",
    "    elif encodedLabel == 3:\n",
    "        return 3\n",
    "    elif encodedLabel == 4:\n",
    "        return 4\n",
    "    elif encodedLabel == 5:\n",
    "        return 5\n",
    "    elif encodedLabel == 6:\n",
    "        return 6\n",
    "    elif encodedLabel == 7:\n",
    "        return 7\n",
    "    elif encodedLabel == 8:\n",
    "        return 8\n",
    "    elif encodedLabel == 9:\n",
    "        return 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedTrainingData  = np.array(training_img)\n",
    "processedTrainingLabel = encodeLabel(training_label)\n",
    "processedTestingData   = np.array(testing_img)\n",
    "processedTestingLabel  = encodeLabel(testing_label)\n",
    "processedUSPSData      = np.array(USPSMat)\n",
    "processedUSPSLabel     = encodeLabel(USPSTar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "input_size = 784\n",
    "drop_out = 0.2\n",
    "first_dense_layer_nodes  = 650\n",
    "second_dense_layer_nodes = 10\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(first_dense_layer_nodes, input_dim=input_size))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(drop_out))\n",
    "    \n",
    "    model.add(Dense(second_dense_layer_nodes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 650)               510250    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 650)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 650)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                6510      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 516,760\n",
      "Trainable params: 516,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 2.3047 - acc: 0.1766 - val_loss: 1.5319 - val_acc: 0.5974\n",
      "Epoch 2/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 1.5403 - acc: 0.5811 - val_loss: 1.2936 - val_acc: 0.6343\n",
      "Epoch 3/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 1.2994 - acc: 0.6322 - val_loss: 1.0445 - val_acc: 0.6777\n",
      "Epoch 4/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 1.0462 - acc: 0.6795 - val_loss: 0.9249 - val_acc: 0.7440\n",
      "Epoch 5/1000\n",
      "40000/40000 [==============================] - 5s 130us/step - loss: 0.9261 - acc: 0.7426 - val_loss: 0.8467 - val_acc: 0.7636\n",
      "Epoch 6/1000\n",
      "40000/40000 [==============================] - 5s 137us/step - loss: 0.8496 - acc: 0.7584 - val_loss: 0.7742 - val_acc: 0.7890\n",
      "Epoch 7/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.7733 - acc: 0.7881 - val_loss: 0.6682 - val_acc: 0.8398\n",
      "Epoch 8/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.6649 - acc: 0.8408 - val_loss: 0.6301 - val_acc: 0.8364\n",
      "Epoch 9/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.6310 - acc: 0.8309 - val_loss: 0.5927 - val_acc: 0.8516\n",
      "Epoch 10/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.5869 - acc: 0.8537 - val_loss: 0.5776 - val_acc: 0.8381\n",
      "Epoch 11/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.5821 - acc: 0.8366 - val_loss: 0.5758 - val_acc: 0.8292\n",
      "Epoch 12/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.5649 - acc: 0.8354 - val_loss: 0.5884 - val_acc: 0.8080\n",
      "Epoch 13/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.5991 - acc: 0.8073 - val_loss: 0.5513 - val_acc: 0.8325\n",
      "Epoch 14/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.5431 - acc: 0.8356 - val_loss: 0.5065 - val_acc: 0.8590\n",
      "Epoch 15/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.5105 - acc: 0.8544 - val_loss: 0.4803 - val_acc: 0.8680\n",
      "Epoch 16/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.4727 - acc: 0.8682 - val_loss: 0.4500 - val_acc: 0.8846\n",
      "Epoch 17/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.4494 - acc: 0.8837 - val_loss: 0.4366 - val_acc: 0.8852\n",
      "Epoch 18/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.4294 - acc: 0.8866 - val_loss: 0.4220 - val_acc: 0.8922\n",
      "Epoch 19/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.4181 - acc: 0.8944 - val_loss: 0.4148 - val_acc: 0.8885\n",
      "Epoch 20/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.4081 - acc: 0.8916 - val_loss: 0.4098 - val_acc: 0.8892\n",
      "Epoch 21/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.4040 - acc: 0.8955 - val_loss: 0.4119 - val_acc: 0.8816\n",
      "Epoch 22/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.4060 - acc: 0.8859 - val_loss: 0.4142 - val_acc: 0.8821\n",
      "Epoch 23/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.4052 - acc: 0.8875 - val_loss: 0.4238 - val_acc: 0.8694\n",
      "Epoch 24/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.4203 - acc: 0.8728 - val_loss: 0.4121 - val_acc: 0.8813\n",
      "Epoch 25/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.4008 - acc: 0.8853 - val_loss: 0.3994 - val_acc: 0.8797\n",
      "Epoch 26/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.3957 - acc: 0.8834 - val_loss: 0.3964 - val_acc: 0.8895\n",
      "Epoch 27/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.3862 - acc: 0.8903 - val_loss: 0.3762 - val_acc: 0.8923\n",
      "Epoch 28/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.3698 - acc: 0.8957 - val_loss: 0.3796 - val_acc: 0.8942\n",
      "Epoch 29/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.3705 - acc: 0.8952 - val_loss: 0.3709 - val_acc: 0.8949\n",
      "Epoch 30/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.3597 - acc: 0.9002 - val_loss: 0.3673 - val_acc: 0.8950\n",
      "Epoch 31/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.3589 - acc: 0.8959 - val_loss: 0.3656 - val_acc: 0.8985\n",
      "Epoch 32/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.3535 - acc: 0.9029 - val_loss: 0.3483 - val_acc: 0.8992\n",
      "Epoch 33/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.3401 - acc: 0.9018 - val_loss: 0.3467 - val_acc: 0.9064\n",
      "Epoch 34/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.3339 - acc: 0.9101 - val_loss: 0.3345 - val_acc: 0.9033\n",
      "Epoch 35/1000\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.3250 - acc: 0.9071 - val_loss: 0.3359 - val_acc: 0.9097\n",
      "Epoch 36/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.3228 - acc: 0.9130 - val_loss: 0.3387 - val_acc: 0.8976\n",
      "Epoch 37/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.3239 - acc: 0.9031 - val_loss: 0.3439 - val_acc: 0.9022\n",
      "Epoch 38/1000\n",
      "40000/40000 [==============================] - 5s 130us/step - loss: 0.3326 - acc: 0.9061 - val_loss: 0.3511 - val_acc: 0.8894\n",
      "Epoch 39/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.3359 - acc: 0.8956 - val_loss: 0.3397 - val_acc: 0.9021\n",
      "Epoch 40/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.3315 - acc: 0.9050 - val_loss: 0.3280 - val_acc: 0.8993\n",
      "Epoch 41/1000\n",
      "40000/40000 [==============================] - 5s 130us/step - loss: 0.3085 - acc: 0.9088 - val_loss: 0.3088 - val_acc: 0.9133\n",
      "Epoch 42/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.2989 - acc: 0.9182 - val_loss: 0.3091 - val_acc: 0.9089\n",
      "Epoch 43/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.2899 - acc: 0.9169 - val_loss: 0.2989 - val_acc: 0.9164\n",
      "Epoch 44/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.2886 - acc: 0.9193 - val_loss: 0.3090 - val_acc: 0.9089\n",
      "Epoch 45/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.2878 - acc: 0.9175 - val_loss: 0.3027 - val_acc: 0.9134\n",
      "Epoch 46/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.2914 - acc: 0.9156 - val_loss: 0.3152 - val_acc: 0.9058\n",
      "Epoch 47/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.2918 - acc: 0.9155 - val_loss: 0.3000 - val_acc: 0.9120\n",
      "Epoch 48/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.2898 - acc: 0.9165 - val_loss: 0.3081 - val_acc: 0.9089\n",
      "Epoch 49/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.2843 - acc: 0.9193 - val_loss: 0.2869 - val_acc: 0.9185\n",
      "Epoch 50/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.2746 - acc: 0.9223 - val_loss: 0.2925 - val_acc: 0.9152\n",
      "Epoch 51/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.2721 - acc: 0.9230 - val_loss: 0.2810 - val_acc: 0.9206\n",
      "Epoch 52/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.2644 - acc: 0.9266 - val_loss: 0.2850 - val_acc: 0.9179\n",
      "Epoch 53/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.2655 - acc: 0.9245 - val_loss: 0.2869 - val_acc: 0.9160\n",
      "Epoch 54/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.2673 - acc: 0.9257 - val_loss: 0.2883 - val_acc: 0.9171\n",
      "Epoch 55/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.2695 - acc: 0.9219 - val_loss: 0.2950 - val_acc: 0.9142\n",
      "Epoch 56/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.2703 - acc: 0.9223 - val_loss: 0.2776 - val_acc: 0.9198\n",
      "Epoch 57/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.2611 - acc: 0.9245 - val_loss: 0.2806 - val_acc: 0.9191\n",
      "Epoch 58/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.2558 - acc: 0.9277 - val_loss: 0.2650 - val_acc: 0.9246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.2458 - acc: 0.9305 - val_loss: 0.2751 - val_acc: 0.9192\n",
      "Epoch 60/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.2497 - acc: 0.9266 - val_loss: 0.2783 - val_acc: 0.9200\n",
      "Epoch 61/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.2581 - acc: 0.9250 - val_loss: 0.2915 - val_acc: 0.9092\n",
      "Epoch 62/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.2670 - acc: 0.9174 - val_loss: 0.2782 - val_acc: 0.9204\n",
      "Epoch 63/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.2570 - acc: 0.9266 - val_loss: 0.2637 - val_acc: 0.9205\n",
      "Epoch 64/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.2399 - acc: 0.9286 - val_loss: 0.2515 - val_acc: 0.9288\n",
      "Epoch 65/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.2278 - acc: 0.9370 - val_loss: 0.2442 - val_acc: 0.9295\n",
      "Epoch 66/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.2203 - acc: 0.9379 - val_loss: 0.2420 - val_acc: 0.9315\n",
      "Epoch 67/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.2188 - acc: 0.9390 - val_loss: 0.2394 - val_acc: 0.9311\n",
      "Epoch 68/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.2144 - acc: 0.9393 - val_loss: 0.2405 - val_acc: 0.9315\n",
      "Epoch 69/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.2144 - acc: 0.9402 - val_loss: 0.2431 - val_acc: 0.9289\n",
      "Epoch 70/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.2165 - acc: 0.9373 - val_loss: 0.2504 - val_acc: 0.9282\n",
      "Epoch 71/1000\n",
      "40000/40000 [==============================] - 5s 118us/step - loss: 0.2256 - acc: 0.9375 - val_loss: 0.2688 - val_acc: 0.9181\n",
      "Epoch 72/1000\n",
      "40000/40000 [==============================] - 5s 113us/step - loss: 0.2394 - acc: 0.9279 - val_loss: 0.2664 - val_acc: 0.9227\n",
      "Epoch 73/1000\n",
      "40000/40000 [==============================] - 5s 128us/step - loss: 0.2446 - acc: 0.9294 - val_loss: 0.2778 - val_acc: 0.9142\n",
      "Epoch 74/1000\n",
      "40000/40000 [==============================] - 5s 130us/step - loss: 0.2441 - acc: 0.9255 - val_loss: 0.2432 - val_acc: 0.9284\n",
      "Epoch 75/1000\n",
      "40000/40000 [==============================] - 5s 115us/step - loss: 0.2212 - acc: 0.9362 - val_loss: 0.2401 - val_acc: 0.9297\n",
      "Epoch 76/1000\n",
      "40000/40000 [==============================] - 5s 128us/step - loss: 0.2075 - acc: 0.9409 - val_loss: 0.2239 - val_acc: 0.9353\n",
      "Epoch 77/1000\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1981 - acc: 0.9446 - val_loss: 0.2262 - val_acc: 0.9337\n",
      "Epoch 78/1000\n",
      "40000/40000 [==============================] - 5s 130us/step - loss: 0.1949 - acc: 0.9452 - val_loss: 0.2194 - val_acc: 0.9370\n",
      "Epoch 79/1000\n",
      "40000/40000 [==============================] - 5s 130us/step - loss: 0.1924 - acc: 0.9463 - val_loss: 0.2246 - val_acc: 0.9363\n",
      "Epoch 80/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.1915 - acc: 0.9463 - val_loss: 0.2221 - val_acc: 0.9351\n",
      "Epoch 81/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.1943 - acc: 0.9451 - val_loss: 0.2309 - val_acc: 0.9343\n",
      "Epoch 82/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.1976 - acc: 0.9453 - val_loss: 0.2323 - val_acc: 0.9295\n",
      "Epoch 83/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.2045 - acc: 0.9408 - val_loss: 0.2395 - val_acc: 0.9310\n",
      "Epoch 84/1000\n",
      "40000/40000 [==============================] - 5s 135us/step - loss: 0.2048 - acc: 0.9416 - val_loss: 0.2454 - val_acc: 0.9215\n",
      "Epoch 85/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.2164 - acc: 0.9335 - val_loss: 0.2515 - val_acc: 0.9258\n",
      "Epoch 86/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.2194 - acc: 0.9331 - val_loss: 0.2445 - val_acc: 0.9248\n",
      "Epoch 87/1000\n",
      "40000/40000 [==============================] - 5s 135us/step - loss: 0.2125 - acc: 0.9340 - val_loss: 0.2245 - val_acc: 0.9353\n",
      "Epoch 88/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1931 - acc: 0.9447 - val_loss: 0.2107 - val_acc: 0.9377\n",
      "Epoch 89/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1789 - acc: 0.9492 - val_loss: 0.2037 - val_acc: 0.9430\n",
      "Epoch 90/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1719 - acc: 0.9522 - val_loss: 0.2029 - val_acc: 0.9408\n",
      "Epoch 91/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1686 - acc: 0.9525 - val_loss: 0.1998 - val_acc: 0.9424\n",
      "Epoch 92/1000\n",
      "40000/40000 [==============================] - 6s 138us/step - loss: 0.1675 - acc: 0.9531 - val_loss: 0.2049 - val_acc: 0.9385\n",
      "Epoch 93/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1680 - acc: 0.9525 - val_loss: 0.2058 - val_acc: 0.9394\n",
      "Epoch 94/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1739 - acc: 0.9505 - val_loss: 0.2287 - val_acc: 0.9311\n",
      "Epoch 95/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1887 - acc: 0.9454 - val_loss: 0.2312 - val_acc: 0.9300\n",
      "Epoch 96/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1993 - acc: 0.9401 - val_loss: 0.2364 - val_acc: 0.9292\n",
      "Epoch 97/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1972 - acc: 0.9427 - val_loss: 0.2133 - val_acc: 0.9377\n",
      "Epoch 98/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1770 - acc: 0.9491 - val_loss: 0.2028 - val_acc: 0.9401\n",
      "Epoch 99/1000\n",
      "40000/40000 [==============================] - 5s 136us/step - loss: 0.1690 - acc: 0.9535 - val_loss: 0.2076 - val_acc: 0.9387\n",
      "Epoch 100/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1684 - acc: 0.9514 - val_loss: 0.2002 - val_acc: 0.9416\n",
      "Epoch 101/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1689 - acc: 0.9533 - val_loss: 0.2139 - val_acc: 0.9361\n",
      "Epoch 102/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1730 - acc: 0.9482 - val_loss: 0.1999 - val_acc: 0.9413\n",
      "Epoch 103/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1693 - acc: 0.9522 - val_loss: 0.2082 - val_acc: 0.9372\n",
      "Epoch 104/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1667 - acc: 0.9512 - val_loss: 0.1931 - val_acc: 0.9438\n",
      "Epoch 105/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1597 - acc: 0.9552 - val_loss: 0.1977 - val_acc: 0.9404\n",
      "Epoch 106/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1558 - acc: 0.9547 - val_loss: 0.1892 - val_acc: 0.9440\n",
      "Epoch 107/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1536 - acc: 0.9573 - val_loss: 0.1958 - val_acc: 0.9412\n",
      "Epoch 108/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1552 - acc: 0.9543 - val_loss: 0.1961 - val_acc: 0.9420\n",
      "Epoch 109/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1586 - acc: 0.9545 - val_loss: 0.2064 - val_acc: 0.9360\n",
      "Epoch 110/1000\n",
      "40000/40000 [==============================] - 5s 136us/step - loss: 0.1670 - acc: 0.9489 - val_loss: 0.2105 - val_acc: 0.9369\n",
      "Epoch 111/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1701 - acc: 0.9500 - val_loss: 0.2051 - val_acc: 0.9373\n",
      "Epoch 112/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1675 - acc: 0.9489 - val_loss: 0.1993 - val_acc: 0.9408\n",
      "Epoch 113/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1571 - acc: 0.9553 - val_loss: 0.1856 - val_acc: 0.9444\n",
      "Epoch 114/1000\n",
      "40000/40000 [==============================] - 5s 135us/step - loss: 0.1481 - acc: 0.9574 - val_loss: 0.1857 - val_acc: 0.9446\n",
      "Epoch 115/1000\n",
      "40000/40000 [==============================] - 5s 135us/step - loss: 0.1429 - acc: 0.9596 - val_loss: 0.1783 - val_acc: 0.9469\n",
      "Epoch 116/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1401 - acc: 0.9608 - val_loss: 0.1840 - val_acc: 0.9458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1400 - acc: 0.9604 - val_loss: 0.1788 - val_acc: 0.9472\n",
      "Epoch 118/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1400 - acc: 0.9612 - val_loss: 0.1874 - val_acc: 0.9451\n",
      "Epoch 119/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1427 - acc: 0.9591 - val_loss: 0.1845 - val_acc: 0.9449\n",
      "Epoch 120/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1457 - acc: 0.9578 - val_loss: 0.1988 - val_acc: 0.9399\n",
      "Epoch 121/1000\n",
      "40000/40000 [==============================] - 5s 137us/step - loss: 0.1532 - acc: 0.9557 - val_loss: 0.1943 - val_acc: 0.9418\n",
      "Epoch 122/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1538 - acc: 0.9551 - val_loss: 0.1943 - val_acc: 0.9422\n",
      "Epoch 123/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1486 - acc: 0.9566 - val_loss: 0.1812 - val_acc: 0.9451\n",
      "Epoch 124/1000\n",
      "40000/40000 [==============================] - 5s 135us/step - loss: 0.1390 - acc: 0.9604 - val_loss: 0.1767 - val_acc: 0.9477\n",
      "Epoch 125/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1333 - acc: 0.9625 - val_loss: 0.1743 - val_acc: 0.9475\n",
      "Epoch 126/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1299 - acc: 0.9639 - val_loss: 0.1723 - val_acc: 0.9483\n",
      "Epoch 127/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1314 - acc: 0.9625 - val_loss: 0.1796 - val_acc: 0.9446\n",
      "Epoch 128/1000\n",
      "40000/40000 [==============================] - 5s 118us/step - loss: 0.1315 - acc: 0.9629 - val_loss: 0.1775 - val_acc: 0.9440\n",
      "Epoch 129/1000\n",
      "40000/40000 [==============================] - 5s 121us/step - loss: 0.1360 - acc: 0.9604 - val_loss: 0.1923 - val_acc: 0.9407\n",
      "Epoch 130/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.1409 - acc: 0.9596 - val_loss: 0.1839 - val_acc: 0.9420\n",
      "Epoch 131/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1430 - acc: 0.9585 - val_loss: 0.1944 - val_acc: 0.9413\n",
      "Epoch 132/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1434 - acc: 0.9579 - val_loss: 0.1786 - val_acc: 0.9467\n",
      "Epoch 133/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.1361 - acc: 0.9593 - val_loss: 0.1796 - val_acc: 0.9478\n",
      "Epoch 134/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1321 - acc: 0.9622 - val_loss: 0.1756 - val_acc: 0.9466\n",
      "Epoch 135/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1297 - acc: 0.9613 - val_loss: 0.1736 - val_acc: 0.9489\n",
      "Epoch 136/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1288 - acc: 0.9635 - val_loss: 0.1747 - val_acc: 0.9473\n",
      "Epoch 137/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1252 - acc: 0.9636 - val_loss: 0.1682 - val_acc: 0.9507\n",
      "Epoch 138/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.1237 - acc: 0.9651 - val_loss: 0.1704 - val_acc: 0.9484\n",
      "Epoch 139/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1194 - acc: 0.9659 - val_loss: 0.1636 - val_acc: 0.9513\n",
      "Epoch 140/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1195 - acc: 0.9653 - val_loss: 0.1684 - val_acc: 0.9493\n",
      "Epoch 141/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1177 - acc: 0.9665 - val_loss: 0.1613 - val_acc: 0.9524\n",
      "Epoch 142/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.1171 - acc: 0.9669 - val_loss: 0.1690 - val_acc: 0.9489\n",
      "Epoch 143/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1168 - acc: 0.9663 - val_loss: 0.1621 - val_acc: 0.9534\n",
      "Epoch 144/1000\n",
      "40000/40000 [==============================] - 5s 135us/step - loss: 0.1183 - acc: 0.9666 - val_loss: 0.1752 - val_acc: 0.9470\n",
      "Epoch 145/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1215 - acc: 0.9644 - val_loss: 0.1705 - val_acc: 0.9497\n",
      "Epoch 146/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1260 - acc: 0.9632 - val_loss: 0.1868 - val_acc: 0.9426\n",
      "Epoch 147/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1333 - acc: 0.9606 - val_loss: 0.1739 - val_acc: 0.9493\n",
      "Epoch 148/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1260 - acc: 0.9630 - val_loss: 0.1692 - val_acc: 0.9476\n",
      "Epoch 149/1000\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.1178 - acc: 0.9660 - val_loss: 0.1612 - val_acc: 0.9514\n",
      "Epoch 150/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1107 - acc: 0.9686 - val_loss: 0.1558 - val_acc: 0.9537\n",
      "Epoch 151/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.1059 - acc: 0.9709 - val_loss: 0.1567 - val_acc: 0.9527\n",
      "Epoch 152/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1049 - acc: 0.9707 - val_loss: 0.1563 - val_acc: 0.9525\n",
      "Epoch 153/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1069 - acc: 0.9701 - val_loss: 0.1622 - val_acc: 0.9505\n",
      "Epoch 154/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.1089 - acc: 0.9679 - val_loss: 0.1669 - val_acc: 0.9490\n",
      "Epoch 155/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1169 - acc: 0.9667 - val_loss: 0.1711 - val_acc: 0.9473\n",
      "Epoch 156/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1183 - acc: 0.9640 - val_loss: 0.1680 - val_acc: 0.9489\n",
      "Epoch 157/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.1170 - acc: 0.9661 - val_loss: 0.1584 - val_acc: 0.9514\n",
      "Epoch 158/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1073 - acc: 0.9693 - val_loss: 0.1544 - val_acc: 0.9533\n",
      "Epoch 159/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.1018 - acc: 0.9724 - val_loss: 0.1498 - val_acc: 0.9552\n",
      "Epoch 160/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0994 - acc: 0.9718 - val_loss: 0.1544 - val_acc: 0.9535\n",
      "Epoch 161/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0997 - acc: 0.9721 - val_loss: 0.1504 - val_acc: 0.9549\n",
      "Epoch 162/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1003 - acc: 0.9715 - val_loss: 0.1616 - val_acc: 0.9497\n",
      "Epoch 163/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1033 - acc: 0.9706 - val_loss: 0.1554 - val_acc: 0.9531\n",
      "Epoch 164/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.1065 - acc: 0.9692 - val_loss: 0.1675 - val_acc: 0.9486\n",
      "Epoch 165/1000\n",
      "40000/40000 [==============================] - 5s 114us/step - loss: 0.1067 - acc: 0.9688 - val_loss: 0.1527 - val_acc: 0.9545\n",
      "Epoch 166/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1024 - acc: 0.9706 - val_loss: 0.1581 - val_acc: 0.9528\n",
      "Epoch 167/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0990 - acc: 0.9723 - val_loss: 0.1482 - val_acc: 0.9551\n",
      "Epoch 168/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0981 - acc: 0.9721 - val_loss: 0.1604 - val_acc: 0.9538\n",
      "Epoch 169/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.1021 - acc: 0.9713 - val_loss: 0.1556 - val_acc: 0.9525\n",
      "Epoch 170/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1044 - acc: 0.9704 - val_loss: 0.1591 - val_acc: 0.9557\n",
      "Epoch 171/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.1009 - acc: 0.9715 - val_loss: 0.1491 - val_acc: 0.9560\n",
      "Epoch 172/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0972 - acc: 0.9728 - val_loss: 0.1539 - val_acc: 0.9547\n",
      "Epoch 173/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.0959 - acc: 0.9736 - val_loss: 0.1523 - val_acc: 0.9534\n",
      "Epoch 174/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0994 - acc: 0.9712 - val_loss: 0.1621 - val_acc: 0.9504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.1025 - acc: 0.9705 - val_loss: 0.1573 - val_acc: 0.9514\n",
      "Epoch 176/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.1026 - acc: 0.9697 - val_loss: 0.1568 - val_acc: 0.9523\n",
      "Epoch 177/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0978 - acc: 0.9719 - val_loss: 0.1458 - val_acc: 0.9560\n",
      "Epoch 178/1000\n",
      "40000/40000 [==============================] - 5s 135us/step - loss: 0.0919 - acc: 0.9740 - val_loss: 0.1470 - val_acc: 0.9555\n",
      "Epoch 179/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0888 - acc: 0.9751 - val_loss: 0.1423 - val_acc: 0.9574\n",
      "Epoch 180/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0873 - acc: 0.9758 - val_loss: 0.1506 - val_acc: 0.9547\n",
      "Epoch 181/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0918 - acc: 0.9741 - val_loss: 0.1493 - val_acc: 0.9558\n",
      "Epoch 182/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0961 - acc: 0.9721 - val_loss: 0.1605 - val_acc: 0.9511\n",
      "Epoch 183/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.1001 - acc: 0.9706 - val_loss: 0.1496 - val_acc: 0.9551\n",
      "Epoch 184/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0951 - acc: 0.9725 - val_loss: 0.1499 - val_acc: 0.9546\n",
      "Epoch 185/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0903 - acc: 0.9743 - val_loss: 0.1383 - val_acc: 0.9587\n",
      "Epoch 186/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0832 - acc: 0.9771 - val_loss: 0.1376 - val_acc: 0.9586\n",
      "Epoch 187/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0802 - acc: 0.9778 - val_loss: 0.1353 - val_acc: 0.9591\n",
      "Epoch 188/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0788 - acc: 0.9786 - val_loss: 0.1345 - val_acc: 0.9594\n",
      "Epoch 189/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0775 - acc: 0.9792 - val_loss: 0.1359 - val_acc: 0.9589\n",
      "Epoch 190/1000\n",
      "40000/40000 [==============================] - 5s 129us/step - loss: 0.0763 - acc: 0.9799 - val_loss: 0.1347 - val_acc: 0.9598\n",
      "Epoch 191/1000\n",
      "40000/40000 [==============================] - 4s 112us/step - loss: 0.0784 - acc: 0.9780 - val_loss: 0.1428 - val_acc: 0.9560\n",
      "Epoch 192/1000\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.0809 - acc: 0.9774 - val_loss: 0.1428 - val_acc: 0.9573\n",
      "Epoch 193/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0877 - acc: 0.9747 - val_loss: 0.1644 - val_acc: 0.9500\n",
      "Epoch 194/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0965 - acc: 0.9721 - val_loss: 0.1515 - val_acc: 0.9544\n",
      "Epoch 195/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0969 - acc: 0.9701 - val_loss: 0.1599 - val_acc: 0.9515\n",
      "Epoch 196/1000\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.0923 - acc: 0.9731 - val_loss: 0.1366 - val_acc: 0.9596\n",
      "Epoch 197/1000\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.0814 - acc: 0.9768 - val_loss: 0.1409 - val_acc: 0.9597\n",
      "Epoch 198/1000\n",
      "40000/40000 [==============================] - 5s 120us/step - loss: 0.0783 - acc: 0.9786 - val_loss: 0.1341 - val_acc: 0.9591\n",
      "Epoch 199/1000\n",
      "40000/40000 [==============================] - 5s 114us/step - loss: 0.0773 - acc: 0.9784 - val_loss: 0.1394 - val_acc: 0.9601\n",
      "Epoch 200/1000\n",
      "40000/40000 [==============================] - 5s 113us/step - loss: 0.0781 - acc: 0.9780 - val_loss: 0.1371 - val_acc: 0.9587\n",
      "Epoch 201/1000\n",
      "40000/40000 [==============================] - 5s 115us/step - loss: 0.0789 - acc: 0.9787 - val_loss: 0.1423 - val_acc: 0.9584\n",
      "Epoch 202/1000\n",
      "40000/40000 [==============================] - 5s 118us/step - loss: 0.0802 - acc: 0.9772 - val_loss: 0.1404 - val_acc: 0.9567\n",
      "Epoch 203/1000\n",
      "40000/40000 [==============================] - 5s 114us/step - loss: 0.0813 - acc: 0.9768 - val_loss: 0.1450 - val_acc: 0.9564\n",
      "Epoch 204/1000\n",
      "40000/40000 [==============================] - 5s 113us/step - loss: 0.0820 - acc: 0.9770 - val_loss: 0.1424 - val_acc: 0.9557\n",
      "Epoch 205/1000\n",
      "40000/40000 [==============================] - 5s 113us/step - loss: 0.0817 - acc: 0.9764 - val_loss: 0.1424 - val_acc: 0.9572\n",
      "Epoch 206/1000\n",
      "40000/40000 [==============================] - 4s 112us/step - loss: 0.0803 - acc: 0.9775 - val_loss: 0.1383 - val_acc: 0.9582\n",
      "Epoch 207/1000\n",
      "40000/40000 [==============================] - 5s 117us/step - loss: 0.0770 - acc: 0.9783 - val_loss: 0.1351 - val_acc: 0.9584\n",
      "Epoch 208/1000\n",
      "40000/40000 [==============================] - 5s 113us/step - loss: 0.0733 - acc: 0.9803 - val_loss: 0.1332 - val_acc: 0.9604\n",
      "Epoch 209/1000\n",
      "40000/40000 [==============================] - 4s 112us/step - loss: 0.0716 - acc: 0.9799 - val_loss: 0.1311 - val_acc: 0.9601\n",
      "Epoch 210/1000\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.0691 - acc: 0.9818 - val_loss: 0.1314 - val_acc: 0.9615\n",
      "Epoch 211/1000\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.0693 - acc: 0.9806 - val_loss: 0.1313 - val_acc: 0.9604\n",
      "Epoch 212/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0692 - acc: 0.9818 - val_loss: 0.1334 - val_acc: 0.9598\n",
      "Epoch 213/1000\n",
      "40000/40000 [==============================] - 5s 121us/step - loss: 0.0715 - acc: 0.9800 - val_loss: 0.1377 - val_acc: 0.9581\n",
      "Epoch 214/1000\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.0742 - acc: 0.9795 - val_loss: 0.1425 - val_acc: 0.9580\n",
      "Epoch 215/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0812 - acc: 0.9760 - val_loss: 0.1563 - val_acc: 0.9515\n",
      "Epoch 216/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0895 - acc: 0.9734 - val_loss: 0.1486 - val_acc: 0.9559\n",
      "Epoch 217/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0890 - acc: 0.9735 - val_loss: 0.1482 - val_acc: 0.9547\n",
      "Epoch 218/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0813 - acc: 0.9761 - val_loss: 0.1279 - val_acc: 0.9618\n",
      "Epoch 219/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0680 - acc: 0.9818 - val_loss: 0.1267 - val_acc: 0.9615\n",
      "Epoch 220/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0623 - acc: 0.9833 - val_loss: 0.1228 - val_acc: 0.9635\n",
      "Epoch 221/1000\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.0614 - acc: 0.9843 - val_loss: 0.1238 - val_acc: 0.9624\n",
      "Epoch 222/1000\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.0599 - acc: 0.9842 - val_loss: 0.1228 - val_acc: 0.9629\n",
      "Epoch 223/1000\n",
      "40000/40000 [==============================] - 5s 130us/step - loss: 0.0595 - acc: 0.9850 - val_loss: 0.1238 - val_acc: 0.9633\n",
      "Epoch 224/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0601 - acc: 0.9844 - val_loss: 0.1248 - val_acc: 0.9627\n",
      "Epoch 225/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0616 - acc: 0.9834 - val_loss: 0.1292 - val_acc: 0.9609\n",
      "Epoch 226/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0645 - acc: 0.9818 - val_loss: 0.1370 - val_acc: 0.9586\n",
      "Epoch 227/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0707 - acc: 0.9797 - val_loss: 0.1464 - val_acc: 0.9545\n",
      "Epoch 228/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0788 - acc: 0.9757 - val_loss: 0.1472 - val_acc: 0.9563\n",
      "Epoch 229/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0794 - acc: 0.9763 - val_loss: 0.1374 - val_acc: 0.9581\n",
      "Epoch 230/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0726 - acc: 0.9791 - val_loss: 0.1320 - val_acc: 0.9621\n",
      "Epoch 231/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0645 - acc: 0.9827 - val_loss: 0.1253 - val_acc: 0.9632\n",
      "Epoch 232/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0627 - acc: 0.9826 - val_loss: 0.1307 - val_acc: 0.9625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0625 - acc: 0.9828 - val_loss: 0.1266 - val_acc: 0.9626\n",
      "Epoch 234/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0634 - acc: 0.9827 - val_loss: 0.1331 - val_acc: 0.9622\n",
      "Epoch 235/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0627 - acc: 0.9828 - val_loss: 0.1252 - val_acc: 0.9622\n",
      "Epoch 236/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0627 - acc: 0.9826 - val_loss: 0.1304 - val_acc: 0.9622\n",
      "Epoch 237/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0603 - acc: 0.9839 - val_loss: 0.1225 - val_acc: 0.9633\n",
      "Epoch 238/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0597 - acc: 0.9835 - val_loss: 0.1388 - val_acc: 0.9573\n",
      "Epoch 239/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0648 - acc: 0.9812 - val_loss: 0.1335 - val_acc: 0.9598\n",
      "Epoch 240/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0701 - acc: 0.9794 - val_loss: 0.1433 - val_acc: 0.9555\n",
      "Epoch 241/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0680 - acc: 0.9808 - val_loss: 0.1247 - val_acc: 0.9628\n",
      "Epoch 242/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0604 - acc: 0.9833 - val_loss: 0.1220 - val_acc: 0.9634\n",
      "Epoch 243/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0537 - acc: 0.9859 - val_loss: 0.1172 - val_acc: 0.9648\n",
      "Epoch 244/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0512 - acc: 0.9873 - val_loss: 0.1180 - val_acc: 0.9651\n",
      "Epoch 245/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0504 - acc: 0.9875 - val_loss: 0.1175 - val_acc: 0.9649\n",
      "Epoch 246/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0513 - acc: 0.9865 - val_loss: 0.1184 - val_acc: 0.9653\n",
      "Epoch 247/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0509 - acc: 0.9876 - val_loss: 0.1211 - val_acc: 0.9628\n",
      "Epoch 248/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0535 - acc: 0.9853 - val_loss: 0.1279 - val_acc: 0.9621\n",
      "Epoch 249/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0595 - acc: 0.9830 - val_loss: 0.1439 - val_acc: 0.9566\n",
      "Epoch 250/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0728 - acc: 0.9771 - val_loss: 0.1545 - val_acc: 0.9539\n",
      "Epoch 251/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0855 - acc: 0.9741 - val_loss: 0.1435 - val_acc: 0.9557\n",
      "Epoch 252/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0722 - acc: 0.9777 - val_loss: 0.1248 - val_acc: 0.9632\n",
      "Epoch 253/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0576 - acc: 0.9839 - val_loss: 0.1213 - val_acc: 0.9634\n",
      "Epoch 254/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0526 - acc: 0.9861 - val_loss: 0.1182 - val_acc: 0.9649\n",
      "Epoch 255/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0518 - acc: 0.9862 - val_loss: 0.1210 - val_acc: 0.9635\n",
      "Epoch 256/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0506 - acc: 0.9871 - val_loss: 0.1183 - val_acc: 0.9647\n",
      "Epoch 257/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0515 - acc: 0.9861 - val_loss: 0.1226 - val_acc: 0.9630\n",
      "Epoch 258/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0515 - acc: 0.9868 - val_loss: 0.1188 - val_acc: 0.9645\n",
      "Epoch 259/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0518 - acc: 0.9858 - val_loss: 0.1264 - val_acc: 0.9624\n",
      "Epoch 260/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0530 - acc: 0.9858 - val_loss: 0.1201 - val_acc: 0.9633\n",
      "Epoch 261/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0538 - acc: 0.9852 - val_loss: 0.1298 - val_acc: 0.9619\n",
      "Epoch 262/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0544 - acc: 0.9850 - val_loss: 0.1205 - val_acc: 0.9630\n",
      "Epoch 263/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0537 - acc: 0.9857 - val_loss: 0.1280 - val_acc: 0.9626\n",
      "Epoch 264/1000\n",
      "40000/40000 [==============================] - 5s 128us/step - loss: 0.0529 - acc: 0.9855 - val_loss: 0.1180 - val_acc: 0.9649\n",
      "Epoch 265/1000\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.0510 - acc: 0.9866 - val_loss: 0.1233 - val_acc: 0.9644\n",
      "Epoch 266/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0487 - acc: 0.9870 - val_loss: 0.1155 - val_acc: 0.9654\n",
      "Epoch 267/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0485 - acc: 0.9876 - val_loss: 0.1227 - val_acc: 0.9640\n",
      "Epoch 268/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.0483 - acc: 0.9877 - val_loss: 0.1176 - val_acc: 0.9637\n",
      "Epoch 269/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0494 - acc: 0.9866 - val_loss: 0.1307 - val_acc: 0.9609\n",
      "Epoch 270/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0546 - acc: 0.9843 - val_loss: 0.1259 - val_acc: 0.9625\n",
      "Epoch 271/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0564 - acc: 0.9839 - val_loss: 0.1378 - val_acc: 0.9580\n",
      "Epoch 272/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0594 - acc: 0.9823 - val_loss: 0.1207 - val_acc: 0.9644\n",
      "Epoch 273/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.0501 - acc: 0.9863 - val_loss: 0.1178 - val_acc: 0.9646\n",
      "Epoch 274/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0462 - acc: 0.9882 - val_loss: 0.1141 - val_acc: 0.9662\n",
      "Epoch 275/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0429 - acc: 0.9892 - val_loss: 0.1135 - val_acc: 0.9666\n",
      "Epoch 276/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0427 - acc: 0.9892 - val_loss: 0.1165 - val_acc: 0.9652\n",
      "Epoch 277/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0435 - acc: 0.9887 - val_loss: 0.1188 - val_acc: 0.9646\n",
      "Epoch 278/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0477 - acc: 0.9876 - val_loss: 0.1278 - val_acc: 0.9614\n",
      "Epoch 279/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0530 - acc: 0.9844 - val_loss: 0.1376 - val_acc: 0.9585\n",
      "Epoch 280/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0628 - acc: 0.9814 - val_loss: 0.1362 - val_acc: 0.9572\n",
      "Epoch 281/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0626 - acc: 0.9804 - val_loss: 0.1298 - val_acc: 0.9622\n",
      "Epoch 282/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0545 - acc: 0.9847 - val_loss: 0.1159 - val_acc: 0.9648\n",
      "Epoch 283/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0457 - acc: 0.9884 - val_loss: 0.1154 - val_acc: 0.9665\n",
      "Epoch 284/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0423 - acc: 0.9894 - val_loss: 0.1113 - val_acc: 0.9663\n",
      "Epoch 285/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0406 - acc: 0.9900 - val_loss: 0.1137 - val_acc: 0.9667\n",
      "Epoch 286/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0396 - acc: 0.9898 - val_loss: 0.1105 - val_acc: 0.9670\n",
      "Epoch 287/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0394 - acc: 0.9902 - val_loss: 0.1136 - val_acc: 0.9667\n",
      "Epoch 288/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0385 - acc: 0.9906 - val_loss: 0.1102 - val_acc: 0.9673\n",
      "Epoch 289/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0395 - acc: 0.9905 - val_loss: 0.1206 - val_acc: 0.9639\n",
      "Epoch 290/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0422 - acc: 0.9889 - val_loss: 0.1215 - val_acc: 0.9640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0504 - acc: 0.9858 - val_loss: 0.1532 - val_acc: 0.9538\n",
      "Epoch 292/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0687 - acc: 0.9790 - val_loss: 0.1379 - val_acc: 0.9595\n",
      "Epoch 293/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0666 - acc: 0.9786 - val_loss: 0.1320 - val_acc: 0.9600\n",
      "Epoch 294/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0524 - acc: 0.9847 - val_loss: 0.1112 - val_acc: 0.9667\n",
      "Epoch 295/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0379 - acc: 0.9905 - val_loss: 0.1092 - val_acc: 0.9675\n",
      "Epoch 296/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0365 - acc: 0.9915 - val_loss: 0.1102 - val_acc: 0.9667\n",
      "Epoch 297/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0358 - acc: 0.9916 - val_loss: 0.1089 - val_acc: 0.9677\n",
      "Epoch 298/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0356 - acc: 0.9916 - val_loss: 0.1107 - val_acc: 0.9670\n",
      "Epoch 299/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0358 - acc: 0.9914 - val_loss: 0.1093 - val_acc: 0.9668\n",
      "Epoch 300/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0358 - acc: 0.9919 - val_loss: 0.1128 - val_acc: 0.9670\n",
      "Epoch 301/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0363 - acc: 0.9912 - val_loss: 0.1113 - val_acc: 0.9661\n",
      "Epoch 302/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0378 - acc: 0.9908 - val_loss: 0.1211 - val_acc: 0.9637\n",
      "Epoch 303/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0408 - acc: 0.9889 - val_loss: 0.1193 - val_acc: 0.9632\n",
      "Epoch 304/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0452 - acc: 0.9873 - val_loss: 0.1342 - val_acc: 0.9607\n",
      "Epoch 305/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0495 - acc: 0.9855 - val_loss: 0.1210 - val_acc: 0.9629\n",
      "Epoch 306/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0470 - acc: 0.9861 - val_loss: 0.1258 - val_acc: 0.9635\n",
      "Epoch 307/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0444 - acc: 0.9877 - val_loss: 0.1148 - val_acc: 0.9650\n",
      "Epoch 308/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0399 - acc: 0.9898 - val_loss: 0.1177 - val_acc: 0.9655\n",
      "Epoch 309/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0386 - acc: 0.9902 - val_loss: 0.1154 - val_acc: 0.9643\n",
      "Epoch 310/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0395 - acc: 0.9894 - val_loss: 0.1170 - val_acc: 0.9662\n",
      "Epoch 311/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0394 - acc: 0.9896 - val_loss: 0.1158 - val_acc: 0.9641\n",
      "Epoch 312/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0386 - acc: 0.9897 - val_loss: 0.1154 - val_acc: 0.9659\n",
      "Epoch 313/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0374 - acc: 0.9904 - val_loss: 0.1133 - val_acc: 0.9653\n",
      "Epoch 314/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0359 - acc: 0.9911 - val_loss: 0.1128 - val_acc: 0.9669\n",
      "Epoch 315/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0350 - acc: 0.9913 - val_loss: 0.1107 - val_acc: 0.9663\n",
      "Epoch 316/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0344 - acc: 0.9920 - val_loss: 0.1118 - val_acc: 0.9667\n",
      "Epoch 317/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0335 - acc: 0.9917 - val_loss: 0.1100 - val_acc: 0.9672\n",
      "Epoch 318/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0332 - acc: 0.9917 - val_loss: 0.1126 - val_acc: 0.9669\n",
      "Epoch 319/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0333 - acc: 0.9918 - val_loss: 0.1103 - val_acc: 0.9671\n",
      "Epoch 320/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0349 - acc: 0.9913 - val_loss: 0.1182 - val_acc: 0.9656\n",
      "Epoch 321/1000\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.0363 - acc: 0.9908 - val_loss: 0.1167 - val_acc: 0.9651\n",
      "Epoch 322/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0414 - acc: 0.9887 - val_loss: 0.1356 - val_acc: 0.9597\n",
      "Epoch 323/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0497 - acc: 0.9859 - val_loss: 0.1254 - val_acc: 0.9631\n",
      "Epoch 324/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0490 - acc: 0.9859 - val_loss: 0.1289 - val_acc: 0.9608\n",
      "Epoch 325/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0442 - acc: 0.9870 - val_loss: 0.1126 - val_acc: 0.9661\n",
      "Epoch 326/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0367 - acc: 0.9903 - val_loss: 0.1130 - val_acc: 0.9663\n",
      "Epoch 327/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0331 - acc: 0.9918 - val_loss: 0.1091 - val_acc: 0.9685\n",
      "Epoch 328/1000\n",
      "40000/40000 [==============================] - 4s 112us/step - loss: 0.0317 - acc: 0.9925 - val_loss: 0.1081 - val_acc: 0.9679\n",
      "Epoch 329/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.0300 - acc: 0.9933 - val_loss: 0.1070 - val_acc: 0.9685\n",
      "Epoch 330/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0295 - acc: 0.9934 - val_loss: 0.1073 - val_acc: 0.9675\n",
      "Epoch 331/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0287 - acc: 0.9937 - val_loss: 0.1065 - val_acc: 0.9692\n",
      "Epoch 332/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0288 - acc: 0.9935 - val_loss: 0.1086 - val_acc: 0.9672\n",
      "Epoch 333/1000\n",
      "40000/40000 [==============================] - 5s 130us/step - loss: 0.0288 - acc: 0.9938 - val_loss: 0.1084 - val_acc: 0.9681\n",
      "Epoch 334/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.0302 - acc: 0.9927 - val_loss: 0.1158 - val_acc: 0.9651\n",
      "Epoch 335/1000\n",
      "40000/40000 [==============================] - 5s 120us/step - loss: 0.0328 - acc: 0.9916 - val_loss: 0.1162 - val_acc: 0.9660\n",
      "Epoch 336/1000\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.0368 - acc: 0.9902 - val_loss: 0.1307 - val_acc: 0.9607\n",
      "Epoch 337/1000\n",
      "40000/40000 [==============================] - 5s 117us/step - loss: 0.0429 - acc: 0.9873 - val_loss: 0.1192 - val_acc: 0.9647\n",
      "Epoch 338/1000\n",
      "40000/40000 [==============================] - 5s 124us/step - loss: 0.0402 - acc: 0.9887 - val_loss: 0.1210 - val_acc: 0.9642\n",
      "Epoch 339/1000\n",
      "40000/40000 [==============================] - 5s 118us/step - loss: 0.0365 - acc: 0.9900 - val_loss: 0.1115 - val_acc: 0.9668\n",
      "Epoch 340/1000\n",
      "40000/40000 [==============================] - 5s 121us/step - loss: 0.0313 - acc: 0.9922 - val_loss: 0.1121 - val_acc: 0.9663\n",
      "Epoch 341/1000\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.0319 - acc: 0.9918 - val_loss: 0.1197 - val_acc: 0.9653\n",
      "Epoch 342/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0362 - acc: 0.9902 - val_loss: 0.1245 - val_acc: 0.9619\n",
      "Epoch 343/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0439 - acc: 0.9864 - val_loss: 0.1331 - val_acc: 0.9610\n",
      "Epoch 344/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0449 - acc: 0.9874 - val_loss: 0.1168 - val_acc: 0.9649\n",
      "Epoch 345/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0369 - acc: 0.9896 - val_loss: 0.1109 - val_acc: 0.9679\n",
      "Epoch 346/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0294 - acc: 0.9928 - val_loss: 0.1053 - val_acc: 0.9687\n",
      "Epoch 347/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0263 - acc: 0.9945 - val_loss: 0.1052 - val_acc: 0.9692\n",
      "Epoch 348/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0260 - acc: 0.9943 - val_loss: 0.1053 - val_acc: 0.9681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0252 - acc: 0.9944 - val_loss: 0.1046 - val_acc: 0.9689\n",
      "Epoch 350/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0252 - acc: 0.9948 - val_loss: 0.1066 - val_acc: 0.9680\n",
      "Epoch 351/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0253 - acc: 0.9944 - val_loss: 0.1057 - val_acc: 0.9685\n",
      "Epoch 352/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0260 - acc: 0.9948 - val_loss: 0.1119 - val_acc: 0.9662\n",
      "Epoch 353/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0284 - acc: 0.9927 - val_loss: 0.1119 - val_acc: 0.9663\n",
      "Epoch 354/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0325 - acc: 0.9916 - val_loss: 0.1290 - val_acc: 0.9612\n",
      "Epoch 355/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0406 - acc: 0.9882 - val_loss: 0.1231 - val_acc: 0.9645\n",
      "Epoch 356/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0422 - acc: 0.9877 - val_loss: 0.1274 - val_acc: 0.9614\n",
      "Epoch 357/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0392 - acc: 0.9892 - val_loss: 0.1079 - val_acc: 0.9681\n",
      "Epoch 358/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0290 - acc: 0.9925 - val_loss: 0.1063 - val_acc: 0.9687\n",
      "Epoch 359/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0247 - acc: 0.9947 - val_loss: 0.1036 - val_acc: 0.9700\n",
      "Epoch 360/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0237 - acc: 0.9952 - val_loss: 0.1047 - val_acc: 0.9699\n",
      "Epoch 361/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0232 - acc: 0.9954 - val_loss: 0.1036 - val_acc: 0.9694\n",
      "Epoch 362/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0235 - acc: 0.9954 - val_loss: 0.1063 - val_acc: 0.9697\n",
      "Epoch 363/1000\n",
      "40000/40000 [==============================] - 5s 119us/step - loss: 0.0233 - acc: 0.9952 - val_loss: 0.1039 - val_acc: 0.9692\n",
      "Epoch 364/1000\n",
      "40000/40000 [==============================] - 4s 111us/step - loss: 0.0233 - acc: 0.9952 - val_loss: 0.1088 - val_acc: 0.9695\n",
      "Epoch 365/1000\n",
      "40000/40000 [==============================] - 4s 112us/step - loss: 0.0241 - acc: 0.9944 - val_loss: 0.1060 - val_acc: 0.9687\n",
      "Epoch 366/1000\n",
      "40000/40000 [==============================] - 5s 114us/step - loss: 0.0256 - acc: 0.9941 - val_loss: 0.1188 - val_acc: 0.9671\n",
      "Epoch 367/1000\n",
      "40000/40000 [==============================] - 5s 116us/step - loss: 0.0299 - acc: 0.9920 - val_loss: 0.1178 - val_acc: 0.9651\n",
      "Epoch 368/1000\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.0345 - acc: 0.9905 - val_loss: 0.1363 - val_acc: 0.9612\n",
      "Epoch 369/1000\n",
      "40000/40000 [==============================] - 5s 118us/step - loss: 0.0413 - acc: 0.9878 - val_loss: 0.1204 - val_acc: 0.9635\n",
      "Epoch 370/1000\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.0364 - acc: 0.9894 - val_loss: 0.1224 - val_acc: 0.9635\n",
      "Epoch 371/1000\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.0335 - acc: 0.9908 - val_loss: 0.1130 - val_acc: 0.9660\n",
      "Epoch 372/1000\n",
      "40000/40000 [==============================] - 5s 122us/step - loss: 0.0296 - acc: 0.9918 - val_loss: 0.1092 - val_acc: 0.9681\n",
      "Epoch 373/1000\n",
      "40000/40000 [==============================] - 5s 120us/step - loss: 0.0261 - acc: 0.9936 - val_loss: 0.1060 - val_acc: 0.9681\n",
      "Epoch 374/1000\n",
      "40000/40000 [==============================] - 5s 113us/step - loss: 0.0231 - acc: 0.9951 - val_loss: 0.1052 - val_acc: 0.9699\n",
      "Epoch 375/1000\n",
      "40000/40000 [==============================] - 5s 120us/step - loss: 0.0225 - acc: 0.9951 - val_loss: 0.1048 - val_acc: 0.9685\n",
      "Epoch 376/1000\n",
      "40000/40000 [==============================] - 5s 119us/step - loss: 0.0223 - acc: 0.9953 - val_loss: 0.1054 - val_acc: 0.9700\n",
      "Epoch 377/1000\n",
      "40000/40000 [==============================] - 5s 120us/step - loss: 0.0225 - acc: 0.9952 - val_loss: 0.1059 - val_acc: 0.9687\n",
      "Epoch 378/1000\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.0225 - acc: 0.9953 - val_loss: 0.1069 - val_acc: 0.9698\n",
      "Epoch 379/1000\n",
      "40000/40000 [==============================] - 5s 118us/step - loss: 0.0227 - acc: 0.9947 - val_loss: 0.1076 - val_acc: 0.9671\n",
      "Epoch 380/1000\n",
      "40000/40000 [==============================] - 5s 121us/step - loss: 0.0225 - acc: 0.9953 - val_loss: 0.1090 - val_acc: 0.9683\n",
      "Epoch 381/1000\n",
      "40000/40000 [==============================] - 5s 118us/step - loss: 0.0244 - acc: 0.9944 - val_loss: 0.1097 - val_acc: 0.9660\n",
      "Epoch 382/1000\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.0246 - acc: 0.9944 - val_loss: 0.1124 - val_acc: 0.9676\n",
      "Epoch 383/1000\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.0258 - acc: 0.9937 - val_loss: 0.1126 - val_acc: 0.9663\n",
      "Epoch 384/1000\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.0270 - acc: 0.9937 - val_loss: 0.1163 - val_acc: 0.9663\n",
      "Epoch 385/1000\n",
      "40000/40000 [==============================] - 5s 116us/step - loss: 0.0281 - acc: 0.9930 - val_loss: 0.1147 - val_acc: 0.9668\n",
      "Epoch 386/1000\n",
      "40000/40000 [==============================] - 5s 114us/step - loss: 0.0289 - acc: 0.9922 - val_loss: 0.1201 - val_acc: 0.9653\n",
      "Epoch 387/1000\n",
      "40000/40000 [==============================] - 5s 117us/step - loss: 0.0293 - acc: 0.9923 - val_loss: 0.1137 - val_acc: 0.9674\n",
      "Epoch 388/1000\n",
      "40000/40000 [==============================] - 5s 121us/step - loss: 0.0284 - acc: 0.9926 - val_loss: 0.1163 - val_acc: 0.9669\n",
      "Epoch 389/1000\n",
      "40000/40000 [==============================] - 5s 128us/step - loss: 0.0275 - acc: 0.9933 - val_loss: 0.1091 - val_acc: 0.9675\n",
      "Epoch 390/1000\n",
      "40000/40000 [==============================] - 5s 120us/step - loss: 0.0251 - acc: 0.9941 - val_loss: 0.1091 - val_acc: 0.9673\n",
      "Epoch 391/1000\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.0223 - acc: 0.9952 - val_loss: 0.1038 - val_acc: 0.9700\n",
      "Epoch 392/1000\n",
      "40000/40000 [==============================] - 5s 118us/step - loss: 0.0206 - acc: 0.9959 - val_loss: 0.1059 - val_acc: 0.9681\n",
      "Epoch 393/1000\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.0207 - acc: 0.9954 - val_loss: 0.1048 - val_acc: 0.9696\n",
      "Epoch 394/1000\n",
      "40000/40000 [==============================] - 5s 128us/step - loss: 0.0208 - acc: 0.9957 - val_loss: 0.1079 - val_acc: 0.9684\n",
      "Epoch 395/1000\n",
      "40000/40000 [==============================] - 5s 128us/step - loss: 0.0215 - acc: 0.9950 - val_loss: 0.1106 - val_acc: 0.9682\n",
      "Epoch 396/1000\n",
      "40000/40000 [==============================] - 5s 120us/step - loss: 0.0237 - acc: 0.9944 - val_loss: 0.1154 - val_acc: 0.9661\n",
      "Epoch 397/1000\n",
      "40000/40000 [==============================] - 5s 118us/step - loss: 0.0280 - acc: 0.9918 - val_loss: 0.1227 - val_acc: 0.9643\n",
      "Epoch 398/1000\n",
      "40000/40000 [==============================] - 5s 121us/step - loss: 0.0320 - acc: 0.9911 - val_loss: 0.1184 - val_acc: 0.9657\n",
      "Epoch 399/1000\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 0.0312 - acc: 0.9908 - val_loss: 0.1167 - val_acc: 0.9672\n",
      "Epoch 400/1000\n",
      "40000/40000 [==============================] - 5s 118us/step - loss: 0.0257 - acc: 0.9930 - val_loss: 0.1043 - val_acc: 0.9684\n",
      "Epoch 401/1000\n",
      "40000/40000 [==============================] - 5s 120us/step - loss: 0.0211 - acc: 0.9953 - val_loss: 0.1072 - val_acc: 0.9704\n",
      "Epoch 402/1000\n",
      "40000/40000 [==============================] - 4s 112us/step - loss: 0.0193 - acc: 0.9959 - val_loss: 0.1020 - val_acc: 0.9702\n",
      "Epoch 403/1000\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.0184 - acc: 0.9967 - val_loss: 0.1056 - val_acc: 0.9702\n",
      "Epoch 404/1000\n",
      "40000/40000 [==============================] - 5s 114us/step - loss: 0.0184 - acc: 0.9963 - val_loss: 0.1019 - val_acc: 0.9707\n",
      "Epoch 405/1000\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.0183 - acc: 0.9966 - val_loss: 0.1075 - val_acc: 0.9701\n",
      "Epoch 406/1000\n",
      "40000/40000 [==============================] - 5s 117us/step - loss: 0.0183 - acc: 0.9966 - val_loss: 0.1038 - val_acc: 0.9709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/1000\n",
      "40000/40000 [==============================] - 5s 118us/step - loss: 0.0194 - acc: 0.9959 - val_loss: 0.1136 - val_acc: 0.9690\n",
      "Epoch 408/1000\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.0208 - acc: 0.9950 - val_loss: 0.1093 - val_acc: 0.9694\n",
      "Epoch 409/1000\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.0235 - acc: 0.9948 - val_loss: 0.1208 - val_acc: 0.9672\n",
      "Epoch 410/1000\n",
      "40000/40000 [==============================] - 5s 130us/step - loss: 0.0240 - acc: 0.9941 - val_loss: 0.1112 - val_acc: 0.9696\n",
      "Epoch 411/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.0249 - acc: 0.9940 - val_loss: 0.1139 - val_acc: 0.9689\n",
      "Epoch 412/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.0207 - acc: 0.9955 - val_loss: 0.1030 - val_acc: 0.9706\n",
      "Epoch 413/1000\n",
      "40000/40000 [==============================] - 5s 129us/step - loss: 0.0195 - acc: 0.9960 - val_loss: 0.1085 - val_acc: 0.9704\n",
      "Epoch 414/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0190 - acc: 0.9961 - val_loss: 0.1077 - val_acc: 0.9688\n",
      "Epoch 415/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.0206 - acc: 0.9952 - val_loss: 0.1153 - val_acc: 0.9676\n",
      "Epoch 416/1000\n",
      "40000/40000 [==============================] - 5s 121us/step - loss: 0.0237 - acc: 0.9942 - val_loss: 0.1181 - val_acc: 0.9668\n",
      "Epoch 417/1000\n",
      "40000/40000 [==============================] - 5s 125us/step - loss: 0.0283 - acc: 0.9924 - val_loss: 0.1254 - val_acc: 0.9635\n",
      "Epoch 418/1000\n",
      "40000/40000 [==============================] - 5s 130us/step - loss: 0.0322 - acc: 0.9905 - val_loss: 0.1197 - val_acc: 0.9667\n",
      "Epoch 419/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.0290 - acc: 0.9918 - val_loss: 0.1077 - val_acc: 0.9692\n",
      "Epoch 420/1000\n",
      "40000/40000 [==============================] - 5s 116us/step - loss: 0.0196 - acc: 0.9958 - val_loss: 0.1027 - val_acc: 0.9709\n",
      "Epoch 421/1000\n",
      "40000/40000 [==============================] - 5s 117us/step - loss: 0.0169 - acc: 0.9967 - val_loss: 0.1025 - val_acc: 0.9701\n",
      "Epoch 422/1000\n",
      "40000/40000 [==============================] - 5s 128us/step - loss: 0.0161 - acc: 0.9970 - val_loss: 0.1024 - val_acc: 0.9719\n",
      "Epoch 423/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0161 - acc: 0.9969 - val_loss: 0.1027 - val_acc: 0.9701\n",
      "Epoch 424/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.0157 - acc: 0.9973 - val_loss: 0.1025 - val_acc: 0.9717\n",
      "Epoch 425/1000\n",
      "40000/40000 [==============================] - 5s 129us/step - loss: 0.0152 - acc: 0.9976 - val_loss: 0.1029 - val_acc: 0.9701\n",
      "Epoch 426/1000\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.0153 - acc: 0.9974 - val_loss: 0.1028 - val_acc: 0.9711\n",
      "Epoch 427/1000\n",
      "40000/40000 [==============================] - 5s 120us/step - loss: 0.0156 - acc: 0.9971 - val_loss: 0.1059 - val_acc: 0.9686\n",
      "Epoch 428/1000\n",
      "40000/40000 [==============================] - 5s 115us/step - loss: 0.0165 - acc: 0.9968 - val_loss: 0.1082 - val_acc: 0.9686\n",
      "Epoch 429/1000\n",
      "40000/40000 [==============================] - 5s 118us/step - loss: 0.0189 - acc: 0.9955 - val_loss: 0.1214 - val_acc: 0.9635\n",
      "Epoch 430/1000\n",
      "40000/40000 [==============================] - 5s 120us/step - loss: 0.0261 - acc: 0.9923 - val_loss: 0.1348 - val_acc: 0.9601\n",
      "Epoch 431/1000\n",
      "40000/40000 [==============================] - 5s 115us/step - loss: 0.0386 - acc: 0.9879 - val_loss: 0.1390 - val_acc: 0.9600\n",
      "Epoch 432/1000\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.0442 - acc: 0.9849 - val_loss: 0.1215 - val_acc: 0.9658\n",
      "Epoch 433/1000\n",
      "40000/40000 [==============================] - 5s 115us/step - loss: 0.0262 - acc: 0.9925 - val_loss: 0.1018 - val_acc: 0.9710\n",
      "Epoch 434/1000\n",
      "40000/40000 [==============================] - 5s 119us/step - loss: 0.0162 - acc: 0.9970 - val_loss: 0.1038 - val_acc: 0.9703\n",
      "Epoch 435/1000\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.0151 - acc: 0.9973 - val_loss: 0.1008 - val_acc: 0.9718\n",
      "Epoch 436/1000\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.0145 - acc: 0.9977 - val_loss: 0.1027 - val_acc: 0.9710\n",
      "Epoch 437/1000\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.0143 - acc: 0.9973 - val_loss: 0.1014 - val_acc: 0.9715\n",
      "Epoch 438/1000\n",
      "40000/40000 [==============================] - 5s 115us/step - loss: 0.0141 - acc: 0.9976 - val_loss: 0.1023 - val_acc: 0.9713\n",
      "Epoch 439/1000\n",
      "40000/40000 [==============================] - 5s 126us/step - loss: 0.0136 - acc: 0.9979 - val_loss: 0.1014 - val_acc: 0.9720\n",
      "Epoch 440/1000\n",
      "40000/40000 [==============================] - 5s 130us/step - loss: 0.0135 - acc: 0.9980 - val_loss: 0.1028 - val_acc: 0.9710\n",
      "Epoch 441/1000\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.0136 - acc: 0.9978 - val_loss: 0.1018 - val_acc: 0.9718\n",
      "Epoch 442/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0139 - acc: 0.9977 - val_loss: 0.1043 - val_acc: 0.9705\n",
      "Epoch 443/1000\n",
      "40000/40000 [==============================] - 5s 120us/step - loss: 0.0139 - acc: 0.9980 - val_loss: 0.1031 - val_acc: 0.9711\n",
      "Epoch 444/1000\n",
      "40000/40000 [==============================] - 5s 123us/step - loss: 0.0146 - acc: 0.9971 - val_loss: 0.1103 - val_acc: 0.9692\n",
      "Epoch 445/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0166 - acc: 0.9966 - val_loss: 0.1110 - val_acc: 0.9689\n",
      "Epoch 446/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0209 - acc: 0.9948 - val_loss: 0.1310 - val_acc: 0.9623\n",
      "Epoch 447/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0298 - acc: 0.9912 - val_loss: 0.1256 - val_acc: 0.9649\n",
      "Epoch 448/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0338 - acc: 0.9892 - val_loss: 0.1273 - val_acc: 0.9641\n",
      "Epoch 449/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0288 - acc: 0.9914 - val_loss: 0.1049 - val_acc: 0.9700\n",
      "Epoch 450/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0161 - acc: 0.9965 - val_loss: 0.1016 - val_acc: 0.9712\n",
      "Epoch 451/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0133 - acc: 0.9980 - val_loss: 0.1020 - val_acc: 0.9711\n",
      "Epoch 452/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0126 - acc: 0.9982 - val_loss: 0.1011 - val_acc: 0.9714\n",
      "Epoch 453/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0129 - acc: 0.9980 - val_loss: 0.1020 - val_acc: 0.9714\n",
      "Epoch 454/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0126 - acc: 0.9983 - val_loss: 0.1015 - val_acc: 0.9713\n",
      "Epoch 455/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.0122 - acc: 0.9981 - val_loss: 0.1025 - val_acc: 0.9715\n",
      "Epoch 456/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0124 - acc: 0.9981 - val_loss: 0.1017 - val_acc: 0.9713\n",
      "Epoch 457/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0123 - acc: 0.9981 - val_loss: 0.1031 - val_acc: 0.9714\n",
      "Epoch 458/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0123 - acc: 0.9983 - val_loss: 0.1019 - val_acc: 0.9715\n",
      "Epoch 459/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0128 - acc: 0.9980 - val_loss: 0.1063 - val_acc: 0.9708\n",
      "Epoch 460/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0136 - acc: 0.9977 - val_loss: 0.1057 - val_acc: 0.9696\n",
      "Epoch 461/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0153 - acc: 0.9970 - val_loss: 0.1217 - val_acc: 0.9666\n",
      "Epoch 462/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0220 - acc: 0.9941 - val_loss: 0.1293 - val_acc: 0.9630\n",
      "Epoch 463/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0333 - acc: 0.9891 - val_loss: 0.1385 - val_acc: 0.9613\n",
      "Epoch 464/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0334 - acc: 0.9891 - val_loss: 0.1117 - val_acc: 0.9688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0193 - acc: 0.9948 - val_loss: 0.1031 - val_acc: 0.9711\n",
      "Epoch 466/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0130 - acc: 0.9976 - val_loss: 0.1020 - val_acc: 0.9716\n",
      "Epoch 467/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0118 - acc: 0.9984 - val_loss: 0.1016 - val_acc: 0.9720\n",
      "Epoch 468/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0113 - acc: 0.9985 - val_loss: 0.1019 - val_acc: 0.9722\n",
      "Epoch 469/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0118 - acc: 0.9984 - val_loss: 0.1017 - val_acc: 0.9718\n",
      "Epoch 470/1000\n",
      "40000/40000 [==============================] - 5s 135us/step - loss: 0.0108 - acc: 0.9985 - val_loss: 0.1022 - val_acc: 0.9718\n",
      "Epoch 471/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0113 - acc: 0.9983 - val_loss: 0.1021 - val_acc: 0.9716\n",
      "Epoch 472/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0115 - acc: 0.9981 - val_loss: 0.1041 - val_acc: 0.9711\n",
      "Epoch 473/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.0119 - acc: 0.9979 - val_loss: 0.1040 - val_acc: 0.9720\n",
      "Epoch 474/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0123 - acc: 0.9980 - val_loss: 0.1106 - val_acc: 0.9686\n",
      "Epoch 475/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0143 - acc: 0.9969 - val_loss: 0.1151 - val_acc: 0.9686\n",
      "Epoch 476/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0204 - acc: 0.9947 - val_loss: 0.1388 - val_acc: 0.9618\n",
      "Epoch 477/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0312 - acc: 0.9901 - val_loss: 0.1234 - val_acc: 0.9656\n",
      "Epoch 478/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0265 - acc: 0.9922 - val_loss: 0.1152 - val_acc: 0.9681\n",
      "Epoch 479/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0169 - acc: 0.9960 - val_loss: 0.1025 - val_acc: 0.9709\n",
      "Epoch 480/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0113 - acc: 0.9984 - val_loss: 0.1023 - val_acc: 0.9720\n",
      "Epoch 481/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0110 - acc: 0.9984 - val_loss: 0.1023 - val_acc: 0.9713\n",
      "Epoch 482/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0104 - acc: 0.9987 - val_loss: 0.1019 - val_acc: 0.9720\n",
      "Epoch 483/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0110 - acc: 0.9984 - val_loss: 0.1029 - val_acc: 0.9710\n",
      "Epoch 484/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0109 - acc: 0.9983 - val_loss: 0.1027 - val_acc: 0.9718\n",
      "Epoch 485/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0106 - acc: 0.9983 - val_loss: 0.1038 - val_acc: 0.9705\n",
      "Epoch 486/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0112 - acc: 0.9982 - val_loss: 0.1057 - val_acc: 0.9714\n",
      "Epoch 487/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0118 - acc: 0.9981 - val_loss: 0.1089 - val_acc: 0.9691\n",
      "Epoch 488/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0142 - acc: 0.9969 - val_loss: 0.1184 - val_acc: 0.9665\n",
      "Epoch 489/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0192 - acc: 0.9945 - val_loss: 0.1254 - val_acc: 0.9646\n",
      "Epoch 490/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0271 - acc: 0.9914 - val_loss: 0.1255 - val_acc: 0.9650\n",
      "Epoch 491/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0227 - acc: 0.9936 - val_loss: 0.1075 - val_acc: 0.9689\n",
      "Epoch 492/1000\n",
      "40000/40000 [==============================] - 5s 135us/step - loss: 0.0150 - acc: 0.9966 - val_loss: 0.1047 - val_acc: 0.9721\n",
      "Epoch 493/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0105 - acc: 0.9984 - val_loss: 0.1011 - val_acc: 0.9719\n",
      "Epoch 494/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0102 - acc: 0.9984 - val_loss: 0.1029 - val_acc: 0.9721\n",
      "Epoch 495/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0097 - acc: 0.9988 - val_loss: 0.1018 - val_acc: 0.9720\n",
      "Epoch 496/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0097 - acc: 0.9987 - val_loss: 0.1032 - val_acc: 0.9720\n",
      "Epoch 497/1000\n",
      "40000/40000 [==============================] - 5s 127us/step - loss: 0.0099 - acc: 0.9985 - val_loss: 0.1026 - val_acc: 0.9718\n",
      "Epoch 498/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0097 - acc: 0.9989 - val_loss: 0.1036 - val_acc: 0.9720\n",
      "Epoch 499/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0097 - acc: 0.9987 - val_loss: 0.1030 - val_acc: 0.9713\n",
      "Epoch 500/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0097 - acc: 0.9987 - val_loss: 0.1049 - val_acc: 0.9723\n",
      "Epoch 501/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0100 - acc: 0.9985 - val_loss: 0.1068 - val_acc: 0.9706\n",
      "Epoch 502/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0112 - acc: 0.9981 - val_loss: 0.1129 - val_acc: 0.9700\n",
      "Epoch 503/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0148 - acc: 0.9962 - val_loss: 0.1326 - val_acc: 0.9630\n",
      "Epoch 504/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0270 - acc: 0.9913 - val_loss: 0.1404 - val_acc: 0.9633\n",
      "Epoch 505/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0384 - acc: 0.9868 - val_loss: 0.1328 - val_acc: 0.9638\n",
      "Epoch 506/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0274 - acc: 0.9919 - val_loss: 0.1027 - val_acc: 0.9724\n",
      "Epoch 507/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0114 - acc: 0.9978 - val_loss: 0.1029 - val_acc: 0.9726\n",
      "Epoch 508/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0096 - acc: 0.9987 - val_loss: 0.1012 - val_acc: 0.9724\n",
      "Epoch 509/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0093 - acc: 0.9988 - val_loss: 0.1020 - val_acc: 0.9727\n",
      "Epoch 510/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0089 - acc: 0.9989 - val_loss: 0.1018 - val_acc: 0.9724\n",
      "Epoch 511/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0088 - acc: 0.9989 - val_loss: 0.1021 - val_acc: 0.9724\n",
      "Epoch 512/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0090 - acc: 0.9989 - val_loss: 0.1022 - val_acc: 0.9722\n",
      "Epoch 513/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0086 - acc: 0.9987 - val_loss: 0.1022 - val_acc: 0.9722\n",
      "Epoch 514/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0087 - acc: 0.9989 - val_loss: 0.1025 - val_acc: 0.9721\n",
      "Epoch 515/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0085 - acc: 0.9990 - val_loss: 0.1025 - val_acc: 0.9721\n",
      "Epoch 516/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0085 - acc: 0.9991 - val_loss: 0.1028 - val_acc: 0.9725\n",
      "Epoch 517/1000\n",
      "40000/40000 [==============================] - 5s 131us/step - loss: 0.0086 - acc: 0.9989 - val_loss: 0.1032 - val_acc: 0.9717\n",
      "Epoch 518/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0085 - acc: 0.9990 - val_loss: 0.1030 - val_acc: 0.9720\n",
      "Epoch 519/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0087 - acc: 0.9989 - val_loss: 0.1046 - val_acc: 0.9721\n",
      "Epoch 520/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0089 - acc: 0.9987 - val_loss: 0.1052 - val_acc: 0.9720\n",
      "Epoch 521/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0096 - acc: 0.9985 - val_loss: 0.1082 - val_acc: 0.9710\n",
      "Epoch 522/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0107 - acc: 0.9980 - val_loss: 0.1162 - val_acc: 0.9689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 523/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0148 - acc: 0.9964 - val_loss: 0.1312 - val_acc: 0.9642\n",
      "Epoch 524/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0272 - acc: 0.9911 - val_loss: 0.1430 - val_acc: 0.9620\n",
      "Epoch 525/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0320 - acc: 0.9894 - val_loss: 0.1195 - val_acc: 0.9673\n",
      "Epoch 526/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0190 - acc: 0.9945 - val_loss: 0.1069 - val_acc: 0.9714\n",
      "Epoch 527/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0102 - acc: 0.9983 - val_loss: 0.1025 - val_acc: 0.9714\n",
      "Epoch 528/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0082 - acc: 0.9991 - val_loss: 0.1025 - val_acc: 0.9725\n",
      "Epoch 529/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0078 - acc: 0.9991 - val_loss: 0.1022 - val_acc: 0.9723\n",
      "Epoch 530/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0081 - acc: 0.9989 - val_loss: 0.1027 - val_acc: 0.9723\n",
      "Epoch 531/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0077 - acc: 0.9992 - val_loss: 0.1027 - val_acc: 0.9723\n",
      "Epoch 532/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0080 - acc: 0.9991 - val_loss: 0.1034 - val_acc: 0.9721\n",
      "Epoch 533/1000\n",
      "40000/40000 [==============================] - 5s 134us/step - loss: 0.0076 - acc: 0.9991 - val_loss: 0.1028 - val_acc: 0.9721\n",
      "Epoch 534/1000\n",
      "40000/40000 [==============================] - 5s 133us/step - loss: 0.0077 - acc: 0.9990 - val_loss: 0.1047 - val_acc: 0.9717\n",
      "Epoch 535/1000\n",
      "40000/40000 [==============================] - 5s 132us/step - loss: 0.0078 - acc: 0.9989 - val_loss: 0.1032 - val_acc: 0.9720\n",
      "Epoch 00535: early stopping\n"
     ]
    }
   ],
   "source": [
    "validation_data_split = 0.2\n",
    "num_epochs = 1000\n",
    "model_batch_size = 50000\n",
    "tb_batch_size = 100\n",
    "early_patience = 100\n",
    "\n",
    "tensorboard_cb   = TensorBoard(log_dir='logs', batch_size= tb_batch_size, write_graph= True)\n",
    "earlystopping_cb = EarlyStopping(monitor='val_loss', verbose=1, patience=early_patience, mode='min')\n",
    "\n",
    "# Process Dataset\n",
    "history = model.fit(processedTrainingData\n",
    "                    , processedTrainingLabel\n",
    "                    , validation_split=validation_data_split\n",
    "                    , epochs=num_epochs\n",
    "                    , batch_size=model_batch_size\n",
    "                    , callbacks = [tensorboard_cb,earlystopping_cb]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x0000018789484668>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x00000187894AFDD8>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x000001878952DCF8>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x00000187895A94E0>], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18789042588>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df = pd.DataFrame(history.history)\n",
    "df.plot(subplots=True, grid=True, figsize=(10,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: 220  Correct :9780\n",
      "Testing Accuracy: 97.8\n",
      "Test Confusion Matrix: \n",
      " [[ 973    0    0    3    0    0    1    1    2    0]\n",
      " [   0 1128    3    1    0    1    1    0    1    0]\n",
      " [   5    1 1005    2    3    0    2    7    6    1]\n",
      " [   0    0    1  998    0    2    0    3    4    2]\n",
      " [   1    0    2    1  961    0    3    3    2    9]\n",
      " [   2    0    0   17    1  860    2    3    5    2]\n",
      " [   3    4    0    1    4    4  937    0    5    0]\n",
      " [   1    3   11    5    3    0    0  998    1    6]\n",
      " [   1    0    4    8    4    5    1    5  942    4]\n",
      " [   2    5    0    8    7    3    0    6    0  978]]\n",
      "====================USPS=========================\n",
      "Errors: 13242  Correct :6757\n",
      "USPS Accuracy: 33.78668933446672\n",
      "USPS Confusion Matrix: \n",
      " [[ 278    0  295  139   76  100  262  659   46  145]\n",
      " [  15  288  658  113  406   92   26  243  127   32]\n",
      " [  21   15 1562   66   17   85  141   57   31    4]\n",
      " [   2   16  443 1047    3  338   63   57   25    6]\n",
      " [   6   15  274   58  772   51   71  608  113   32]\n",
      " [   7    2  901  178    5  633  132  100   38    4]\n",
      " [  36   10  611   31   44  200  735  291   29   13]\n",
      " [   4   54  165  504   24   39   29 1081   96    4]\n",
      " [  61    3  186  577   88  219  176  425  257    8]\n",
      " [   3   27  162  325  103   17   30 1008  221  104]]\n"
     ]
    }
   ],
   "source": [
    "wrong   = 0\n",
    "right   = 0\n",
    "uw = 0\n",
    "ur = 0\n",
    "\n",
    "predictedTestLabel = []\n",
    "predictedUSPSLabel = []\n",
    "\n",
    "for i,j in zip(processedTestingData,processedTestingLabel):\n",
    "    y = model.predict(np.array(i).reshape(-1,784))\n",
    "    predictedTestLabel.append(decodeLabel(y.argmax()))\n",
    "    \n",
    "    if j.argmax() == y.argmax():\n",
    "        right = right + 1\n",
    "    else:\n",
    "        wrong = wrong + 1\n",
    "\n",
    "for i,j in zip(processedUSPSData,processedUSPSLabel):\n",
    "    y = model.predict(np.array(i).reshape(-1,784))\n",
    "    predictedUSPSLabel.append(decodeLabel(y.argmax()))\n",
    "    \n",
    "    if j.argmax() == y.argmax():\n",
    "        ur = ur + 1\n",
    "    else:\n",
    "        uw = uw + 1\n",
    "\n",
    "        \n",
    "print(\"Errors: \" + str(wrong), \" Correct :\" + str(right))\n",
    "print(\"Testing Accuracy: \" + str(right/(right+wrong)*100))\n",
    "print(\"Test Confusion Matrix: \\n\",metrics.confusion_matrix(testing_label, predictedTestLabel))\n",
    "print('====================USPS=========================')\n",
    "print(\"Errors: \" + str(uw), \" Correct :\" + str(ur))\n",
    "print(\"USPS Accuracy: \" + str(ur/(ur+uw)*100))\n",
    "print(\"USPS Confusion Matrix: \\n\",metrics.confusion_matrix(USPSTar, predictedUSPSLabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, criterion='entropy')\n",
    "clf.fit(training_img,training_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9722\n"
     ]
    }
   ],
   "source": [
    "validation_prediction = clf.predict(validation_img)\n",
    "print(\"Validation Accuracy: \" + str(accuracy_score(validation_label,validation_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.966\n",
      "Test Confusion Matrix \n",
      " [[ 971    0    1    0    0    1    2    1    3    1]\n",
      " [   0 1121    2    4    0    2    2    0    3    1]\n",
      " [   6    0  998    6    1    0    4   10    7    0]\n",
      " [   0    0   15  965    0    9    0    9    9    3]\n",
      " [   2    0    2    0  949    0    5    0    2   22]\n",
      " [   3    0    0   15    4  852    8    2    6    2]\n",
      " [   7    3    1    0    4    4  934    0    5    0]\n",
      " [   1    2   23    1    2    0    0  986    2   11]\n",
      " [   4    0    4    7    4    7    5    3  927   13]\n",
      " [   6    4    2   11   12    4    1    6    6  957]]\n"
     ]
    }
   ],
   "source": [
    "test_prediction = clf.predict(testing_img)\n",
    "print(\"Test Accuracy: \" + str(accuracy_score(testing_label,test_prediction)))\n",
    "print(\"Test Confusion Matrix \\n\", confusion_matrix(testing_label, test_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USPS Accuracy: 0.386469323466\n",
      "USPS Confusion Matrix \n",
      " [[ 599   10  225   51  465  148   71  168    1  262]\n",
      " [  22  601   90  119   51   67   18 1016   15    1]\n",
      " [  78   45 1172   83   58  181   18  356    6    2]\n",
      " [  42   12   86 1240   53  297    1  247    3   19]\n",
      " [   9  236   53   22 1074  136    9  418   20   23]\n",
      " [ 135   33  119   93   39 1379   24  166    3    9]\n",
      " [ 325   70  220   34  109  318  728  182    4   10]\n",
      " [  35  368  327  213   45  242   31  731    2    6]\n",
      " [  62   76  157  201  128 1022   73  135  119   27]\n",
      " [  16  303  224  263  256  122    7  666   57   86]]\n"
     ]
    }
   ],
   "source": [
    "USPS_prediction = clf.predict(USPSMat)\n",
    "print(\"USPS Accuracy: \"+ str(accuracy_score(USPSTar,USPS_prediction)))\n",
    "print(\"USPS Confusion Matrix \\n\", confusion_matrix(USPSTar, USPS_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=3, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.005, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC(probability=False, kernel=\"rbf\", C=3, gamma=.005)\n",
    "classifier.fit(training_img, training_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.977\n"
     ]
    }
   ],
   "source": [
    "ValPredicted = classifier.predict(validation_img)\n",
    "print(\"Validation Accuracy: \", metrics.accuracy_score(validation_label, ValPredicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.9748\n",
      "Confusion matrix: \n",
      " [[ 972    0    0    0    0    2    3    1    2    0]\n",
      " [   0 1126    3    1    0    1    1    1    2    0]\n",
      " [   3    2 1008    2    1    0    1    9    5    1]\n",
      " [   0    0    4  985    0    5    0    7    8    1]\n",
      " [   1    0    5    0  959    0    3    0    2   12]\n",
      " [   5    0    0   13    1  860    4    1    6    2]\n",
      " [   6    2    1    0    2    5  940    0    2    0]\n",
      " [   0    9   14    2    2    0    0  990    1   10]\n",
      " [   3    0    3    9    5    2    3    3  945    1]\n",
      " [   3    6    1    7   14    2    1    8    4  963]]\n"
     ]
    }
   ],
   "source": [
    "predicted = classifier.predict(testing_img)\n",
    "print(\"Testing Accuracy: \", metrics.accuracy_score(testing_label, predicted))\n",
    "print(\"Confusion matrix: \\n\" ,metrics.confusion_matrix(testing_label, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USPS Accuracy:  0.399119955998\n",
      "Confusion matrix: \n",
      " [[ 592    1  397   39  176  330   54   70    2  339]\n",
      " [  87  405  360  144  141  152   26  651   18   16]\n",
      " [  70    6 1617   45   19  163   28   41    6    4]\n",
      " [  28    6  246 1190    1  477    0   43    3    6]\n",
      " [  14   41  164   26  985  282   16  344   51   77]\n",
      " [  66   12  283   68   11 1494   25   28   10    3]\n",
      " [ 147    5  685   24   50  289  771   13    1   15]\n",
      " [  43  144  468  439   25  317    6  528   17   13]\n",
      " [  71    9  258  261   51 1060   57   39  187    7]\n",
      " [  12   83  260  372  131  154    4  621  150  213]]\n"
     ]
    }
   ],
   "source": [
    "USPSPredicted = classifier.predict(USPSMat)\n",
    "print(\"USPS Accuracy: \", metrics.accuracy_score(USPSTar, USPSPredicted))\n",
    "print(\"Confusion matrix: \\n\" ,metrics.confusion_matrix(USPSTar, USPSPredicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENSAMBLING USING MAXIMUM VOTING (HARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Test Accuracy:  0.971\n",
      "Ensemble Test Confusion Matrix: \n",
      " [[ 973    0    1    0    0    0    2    1    3    0]\n",
      " [   0 1126    3    1    0    1    1    0    3    0]\n",
      " [   8    2 1003    2    1    0    1    8    6    1]\n",
      " [   0    0   13  978    0    3    0    5    8    3]\n",
      " [   1    0    3    0  953    0    4    1    2   18]\n",
      " [   5    0    0   21    2  849    4    1    8    2]\n",
      " [   7    3    1    0    4    6  933    0    4    0]\n",
      " [   1    6   22    1    3    0    0  982    1   12]\n",
      " [   3    0    4    8    4    1    4    6  942    2]\n",
      " [   6    7    2    7    7    1    1    4    3  971]]\n",
      "Ensemble USPS Accuracy:  0.4030701535076754\n",
      "Ensemble USPS Confusion Matrix: \n",
      " [[ 647    2  371   58  272  120   86  155   10  279]\n",
      " [  90  427  350  161  223   75   18  548   97   11]\n",
      " [ 110   22 1560   50   31   97   45   66   13    5]\n",
      " [  54    8  240 1332   12  259   12   56   13   14]\n",
      " [  13  103  127   32 1089  138   21  331   99   47]\n",
      " [ 115   16  351  126   16 1246   39   66   19    6]\n",
      " [ 312   13  523   31   74  222  722   75   12   16]\n",
      " [  54  229  370  400   33  171   25  648   60   10]\n",
      " [ 123   28  188  319   94  769   85  127  253   14]\n",
      " [  17  196  210  355  160   88   10  629  198  137]]\n"
     ]
    }
   ],
   "source": [
    "ensemblePredictions     = []\n",
    "USPSensemblePredictions = []\n",
    "\n",
    "er=0\n",
    "ew=0\n",
    "uer=0\n",
    "uew=0\n",
    "\n",
    "for i in range(0,len(testing_label)):\n",
    "    vec=[]\n",
    "    vec.append(LogRegPredictions[i])\n",
    "    vec.append(predictedTestLabel[i])\n",
    "    vec.append(test_prediction[i])\n",
    "    vec.append(predicted[i])\n",
    "    data=Counter(vec)\n",
    "    pr=data.most_common(1)\n",
    "    if(pr[0][1]>1):\n",
    "        ensemblePredictions.append(pr[0][0])\n",
    "    else:\n",
    "        ensemblePredictions.append(predictedTestLabel[i])\n",
    "        \n",
    "    if ensemblePredictions[i]==testing_label[i]:\n",
    "        er = er + 1\n",
    "    else:\n",
    "        ew = ew + 1\n",
    "        \n",
    "for i in range(0,len(USPSTar)):\n",
    "    vec=[]\n",
    "    vec.append(uspsLogRegPredictions[i])\n",
    "    vec.append(predictedUSPSLabel[i])\n",
    "    vec.append(USPS_prediction[i])\n",
    "    vec.append(USPSPredicted[i])\n",
    "    data=Counter(vec)\n",
    "    pr=data.most_common(1)\n",
    "    if(pr[0][1]>1):\n",
    "        USPSensemblePredictions.append(pr[0][0])\n",
    "    else:\n",
    "        USPSensemblePredictions.append(predictedUSPSLabel[i])\n",
    "    \n",
    "    if USPSensemblePredictions[i]==USPSTar[i]:\n",
    "        uer = uer + 1\n",
    "    else:\n",
    "        uew = uew + 1\n",
    "        \n",
    "print(\"Ensemble Test Accuracy: \", str(er/(er+ew)))\n",
    "print(\"Ensemble Test Confusion Matrix: \\n\", metrics.confusion_matrix(testing_label, ensemblePredictions))\n",
    "\n",
    "print(\"Ensemble USPS Accuracy: \", str(uer/(uer+uew)))\n",
    "print(\"Ensemble USPS Confusion Matrix: \\n\", metrics.confusion_matrix(USPSTar, USPSensemblePredictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
